<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="author" content="">
<meta name="description" content="The aim of the project is to inject geometric information into a self-supervised visual representation learning pipeline by integrating depth signals into the process. We explored different strategies to guide the representation learning, using depth prediction as an auxiliary task or via a feature-level guidance strategy. Specifically, the training pipeline for I-JEPA (Image Joint Embedding Predictive Architecture) was augmented with depth supervision signals. The resulting model learns to predict target patches from given context patches while simultaneously being supervised by ground-truth depth maps. The research involved analyzing the trade-offs of different masking strategies and supervision signals, concluding that the approach is a promising direction for creating robust and geometrically-aware world models for scene prediction in autonomous vehicles.
" />
<meta name="keywords" content="" />
<meta name="robots" content="noodp" />
<meta name="theme-color" content="" />
<link rel="canonical" href="https://sergisanchezz.github.io/projects/depth-guided-world-models/" />


    <title>
        
            Towards Depth-Guided Self-Supervised World Models :: Sergi Sanchez Orvay 
        
    </title>





  <link rel="stylesheet" href="/main.min.7289daf2e88ea2c7b253a51cc5794c7cc17e7aeb7295a19d978db764a5862f25.css" integrity="sha256-cona8uiOoseyU6UcxXlMfMF&#43;eutylaGdl423ZKWGLyU=" crossorigin="anonymous">





    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">
    <link rel="mask-icon" href="/safari-pinned-tab.svg" color="">
    <link rel="shortcut icon" href="/favicon.ico">
    <meta name="msapplication-TileColor" content="">



  <meta itemprop="name" content="Towards Depth-Guided Self-Supervised World Models">
  <meta itemprop="description" content="The aim of the project is to inject geometric information into a self-supervised visual representation learning pipeline by integrating depth signals into the process. We explored different strategies to guide the representation learning, using depth prediction as an auxiliary task or via a feature-level guidance strategy. Specifically, the training pipeline for I-JEPA (Image Joint Embedding Predictive Architecture) was augmented with depth supervision signals. The resulting model learns to predict target patches from given context patches while simultaneously being supervised by ground-truth depth maps. The research involved analyzing the trade-offs of different masking strategies and supervision signals, concluding that the approach is a promising direction for creating robust and geometrically-aware world models for scene prediction in autonomous vehicles.">
  <meta itemprop="wordCount" content="117">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Towards Depth-Guided Self-Supervised World Models">
  <meta name="twitter:description" content="The aim of the project is to inject geometric information into a self-supervised visual representation learning pipeline by integrating depth signals into the process. We explored different strategies to guide the representation learning, using depth prediction as an auxiliary task or via a feature-level guidance strategy. Specifically, the training pipeline for I-JEPA (Image Joint Embedding Predictive Architecture) was augmented with depth supervision signals. The resulting model learns to predict target patches from given context patches while simultaneously being supervised by ground-truth depth maps. The research involved analyzing the trade-offs of different masking strategies and supervision signals, concluding that the approach is a promising direction for creating robust and geometrically-aware world models for scene prediction in autonomous vehicles.">


















    </head>

    
        <body>
    
    
        <div class="container">
            <header class="header">
    <span class="header__inner">
        <a href="/" style="text-decoration: none;">
    <div class="logo">
        
            <span class="logo__mark">></span>
            <span class="logo__text ">
                Sergi Sanchez Orvay</span>
            <span class="logo__cursor" style=
                  "
                   
                   ">
            </span>
        
    </div>
</a>


        <span class="header__right">
                <nav class="menu">
    <ul class="menu__inner">
                <li><a href="/about/">About Me</a></li>
            
                <li><a href="/news/">News</a></li>
            
                <li><a href="/projects/">Projects</a></li>
            
                <li><a href="/publications/">Publications</a></li>
            
    </ul>
</nav>


                <span class="menu-trigger">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                        <path d="M0 0h24v24H0z" fill="none"/>
                        <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
                    </svg>
                </span>
        </span>
    </span>
</header>


            
    <div class="post">
        <h1 class="post-title">Towards Depth-Guided Self-Supervised World Models</h1>
        
        
        <div class="post-meta" style="margin-bottom: 20px;">
            Feb 2025 
            – 
            
                Jul 2025
            
        </div>
        

        

        
        <h3 style="margin-top: 25px;">Contributors</h3>
        <p>
            Authors: Juan Tarazona Rodríguez, Ahmed Elgaradiny, Hanqiu Li Cai, Sergi Sánchez Orvay
            
                <br>Supervisors: Mirlan Karimov
            
        </p>
        

        <h3 style="margin-top: 30px;">Abstract</h3>
        <div class="post-content">
            <p>The aim of the project is to inject geometric information into a self-supervised visual representation learning pipeline by integrating depth signals into the process. We explored different strategies to guide the representation learning, using depth prediction as an auxiliary task or via a feature-level guidance strategy. Specifically, the training pipeline for I-JEPA (Image Joint Embedding Predictive Architecture) was augmented with depth supervision signals. The resulting model learns to predict target patches from given context patches while simultaneously being supervised by ground-truth depth maps. The research involved analyzing the trade-offs of different masking strategies and supervision signals, concluding that the approach is a promising direction for creating robust and geometrically-aware world models for scene prediction in autonomous vehicles.</p>

        </div>

        <div class="project-links" style="margin-top: 20px;">
            <h3>Documentation</h3>
            <ul style="list-style: none; padding: 0;">
                
                    <li>
                        <a href="https://github.com/Juan5713/MM_WM_AD" target="_blank">
                        GitHub Repository
                        </a>
                    </li>
                
                
                    <li>
                        <a href="/files/3DV_Report.pdf" target="_blank">
                        Download Report (PDF)
                        </a>
                    </li>
                
                
            </ul>
        </div>

        <p style="margin-top: 40px;"><a href="/projects/">← Back to Projects List</a></p>
    </div>


            
                <footer class="footer">
    
    
</footer>

            
        </div>

        



<script type="text/javascript" src="/bundle.min.08b680078a3cf9c69e3dd217a5aa52cfddd4a1d850f8cdff127fdd7421a71f8b2b474be69386f67819edace92273916e7230c9054f38107db9dc6730b3530ab5.js" integrity="sha512-CLaAB4o8&#43;caePdIXpapSz93UodhQ&#43;M3/En/ddCGnH4srR0vmk4b2eBntrOkic5FucjDJBU84EH253Gcws1MKtQ=="></script>




    </body>
</html>
